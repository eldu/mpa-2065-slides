{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Review Basics of Hypothesis Testing</h1></center>\n",
    "<center><h3>Ellen Duong</h3></center>\n",
    "<center><h3>Paul Stey</h3></center>\n",
    "<center><h3>2023-10-26</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Resources \n",
    " - Discovering Statistics using R, Field, A. _et al_., 2012\n",
    " - Statistical Rethinking, McElreath, R., 2015\n",
    " - All of Statistics, Wasserman, L., 2004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1.1 Review of Core Concepts\n",
    "\t\n",
    "- Bayesians, Frequentists, and Likelihoodists\n",
    "- There are a few approaches to statistical inference:\n",
    "    - Bayesian\n",
    "    - Likelihoodist\n",
    "    - Frequentist\n",
    "\n",
    "We will be concerned primarily with the frequentist approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.1 What is hypothesis testing?\n",
    "<br>\n",
    "<br>\n",
    "<center>Hypothesis testing is the process of using data to make decisions under uncertainty.</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.2 What is hypothesis testing? (cont.)\n",
    "\t\n",
    "The frequentist approach is typically choosing between 2 competing hypotheses.\n",
    "\n",
    "  - Null hypothesis (usually written $H_0$)\n",
    "  - Alternative hypothesis (usually written $H_1$ or sometimes $H_A$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.3 What is hypothesis testing? (cont.)\n",
    "\n",
    "For example, we might be interested in whether some new medication, $M$, reduces cholesterol. Here the competing hypotheses are:\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "\n",
    "  $H_0$: $\\mu_{1} = \\mu_{2}$ $M$ does not reduce cholesterol (null hypothesis)\n",
    "  \n",
    "  $H_1$: $\\mu_{1} < \\mu_{2}$ $M$ reduces cholesterol (alternative hypothesis)\n",
    "\n",
    "<br>\n",
    "</center>\n",
    "\n",
    "where $\\mu_1$ is mean cholesterol for those receiving $M$ in the population, and $\\mu_2$ is mean cholesterol for those _not_ receiving $M$ in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.4 Notes on hypothesis testing\n",
    "\n",
    "Some important things to note:\n",
    "\n",
    "1. Previous example is one-sided test; two-sided tests generally look like:\n",
    "\n",
    "  - $H_0$: $\\mu_{1} = \\mu_{2}$\n",
    "  - $H_1$: $\\mu_{1} \\ne \\mu_{2}$\n",
    "\n",
    "2. Two-sided tests tend to be more common\n",
    "3. You should clearly articulate hypotheses _prior to conducting statistical tests_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1.5 Notes on Hypothesis Testing (cont.)\n",
    "\n",
    "General process of hypothesis testing:\n",
    "\n",
    "1. Specify the null and alternative hypotheses, $H_0$ and $H_1$\n",
    "2. Determine the test to be used, which gives us:\n",
    "\n",
    "  - Our test statistic\n",
    "  - Corresponding probability distribution \n",
    "\n",
    "3. Set a level of significance (e.g., $\\alpha = 0.05$)\n",
    "4. Use our data to compute our test statistic (and perhaps its standard error)\n",
    "5. Use test statistic and its accompanying distribution to obtain _p_-value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Review of _p_-values\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>What is a <i>p</i>-value?</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2.1. Understanding _p_-values\n",
    "\n",
    "A <i>p</i>-value is a probability. In particular, it is the probability of finding data <i>as extreme or more extreme</i> than what he have observed, given that the null hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1.1 Understanding _p_-values (cont.)\n",
    "\n",
    "In other words, a _p_-value can be used to answer this question:\n",
    "\n",
    "<br>\n",
    "\n",
    "  <center><i>If the null hypothesis is true, are my data unusual?</i></center>\n",
    "\n",
    "<br>\n",
    "When a p-value is small, our answer is \"yes\". And when the answer is \"yes\", we are generally inclined to take this as evidence against the null hypothesis.\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1.2 Understanding _p_-values (cont.)\n",
    "\n",
    "A _p_-value is **NOT**:\n",
    "\n",
    "  - The probability the null hypothesis is true\n",
    "  - The probability that the data were produced by chance alone\n",
    "  - A measure of effect size\n",
    "     + Be wary of papers discussing \"highly\" or \"extremely\" significant results based _p_-values\n",
    "     + Also beware of studies using _p_-values as inputs to subsequent computations or tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1.3 Understanding _p_-values (cont.)\n",
    "\n",
    "Other notes on _p_-values:\n",
    "\n",
    "1. Their use is controversial in some circles\n",
    "2. Can be easily abused to show significant results\n",
    "3. Despite limitations, they are ubiquitous in science\n",
    "  - We have used them for so long, it's hard to change course (but Bayesians are trying!)\n",
    "  - For many applied researchers and practitioners, they are a convenient way to turn observed data in to a \"yes\"/\"no\" decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. The Decision Problem\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>Ultimately, we want to be able to draw conclusions and make decisions based on data</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## 3.1 Deciding between $H_0$ and $H_1$\n",
    "<br>\n",
    "\t\t<center>So, how do we choose between our hypotheses?</center>\n",
    "<br>\n",
    "\n",
    "1. Our default is to believe $H_0$\n",
    "\n",
    "2. We use our data to determine if we have sufficient reason to reject $H_0$ \n",
    "\n",
    "3. This is where we rely on work from probability theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1.1 Deciding between $H_0$ and $H_1$ (cont.)\n",
    "<br>\n",
    "<center>Because we are relying on probabilistic reasoning about whether or not to reject $H_0$, we can be wrong.</center>\n",
    "\n",
    "![image](images/error_types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1.2 Deciding between $H_0$ and $H_1$ (cont.)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Question:\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>How do we know when we have committed a Type I error or a Type II error?</center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1.3 Deciding between $H_0$ and $H_1$ (cont.)\n",
    "\n",
    "<br>\n",
    "\n",
    "Answer: \n",
    "<br>\n",
    "\n",
    "<center>In general, we cannot <i>know</i> unequivocally when we have committed a Type I error or a Type II error.</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "This has important implications:\n",
    "\n",
    "1. Replication is _absolutely crucial_ in science\n",
    "2. Must be _hyper vigilant_ about inflated Type I error from repeated testing (more on this later)\n",
    "3. Should be generally skeptical, and especially so for low power studies with \"oh-wow\" results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>The Binomial Test and Categorical Data</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 4. Categorical Data\n",
    "\n",
    "  - Variables representing group members \n",
    "  - Examples: \n",
    "    + Political party affiliation\n",
    "    + City of origin\n",
    "    + Gender\n",
    "    + Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. The Binomial Test\n",
    "  - Probably the most basic example of a hypothesis tests (and very useful)\n",
    "  - Used to compare distribution of observations in two categories against theoretical distribution\n",
    "  - Essentially, we use the binomial test when we have a problem that can be expressed in terms of \"successes\" and \"failures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.1 Binomial Test Examples\n",
    "\n",
    "Example questions we can answer:\n",
    "  - Given $N$ tosses of a coin, $X_1, X_2, ..., X_n$, where $X_i = 1$ denotes heads and $X_i = 0$ is tails, is this a fair coin?\n",
    "  - Given the counts of females and males in a particular class, are there significantly more females than males?\n",
    "  - Suppose we are doing quality control on a medical device known to have a 0.001\\%  failure rate. Given the number of failures in a specific batch and the batch size, does this batch have significantly more failures than we expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.1.1 Review Binomial Distribution\n",
    "\n",
    "1. Discrete probability distribution\n",
    "2. Has two parameter\n",
    "  - $n$: number of \"trials\"\n",
    "  - $p$: probability of \"success\" for a given trial\n",
    "  \n",
    "\n",
    "\n",
    "<center><img src=\"images/binomial_distribution_pmf.png\" width=\"700\"></center>\n",
    "\n",
    "[1.] Image source: wikipedia.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.2 Binomial Test\n",
    "\n",
    "<center><img src=\"images/binomial_plot.png\" width=\"700\"></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.3 Binomial Test: Coin Toss Example\n",
    "\n",
    "Suppose we have the following data after tossing a coin several times:\n",
    "\n",
    "[H, T, T, T, H, H, T, H, T, T, H, T, T, T, T]\n",
    "\n",
    "Is this a fair coin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.3.1 Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 15\n",
      "[1] 5\n"
     ]
    }
   ],
   "source": [
    "# create variable to store data\n",
    "coin_tosses <- c(\"H\", \"T\", \"T\", \"T\", \"H\", \"H\", \"T\", \"H\", \"T\", \"T\", \"H\", \n",
    "                 \"T\", \"T\", \"T\", \"T\")\n",
    "\n",
    "# get number of tosses\n",
    "n_tosses <- length(coin_tosses)\n",
    "\n",
    "# get number of heads\n",
    "n_heads <- sum(coin_tosses == \"H\")\n",
    "\n",
    "# print variables we created to check sanity\n",
    "print(n_tosses)\n",
    "print(n_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.3.2 Using `binom.test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  n_heads and n_tosses\n",
      "number of successes = 5, number of trials = 15, p-value = 0.3018\n",
      "alternative hypothesis: true probability of success is not equal to 0.5\n",
      "95 percent confidence interval:\n",
      " 0.1182411 0.6161963\n",
      "sample estimates:\n",
      "probability of success \n",
      "             0.3333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run binomial test on coin toss data\n",
    "\n",
    "bin_test1 <- binom.test(n_heads, n_tosses)\n",
    "\n",
    "print(bin_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.4 Binomial Test: Device Defects Examples\n",
    "\n",
    "Suppose we are doing quality control for a medical device known to have a 0.0001% failure rate. We are given a batch of 250000 to be tested. Of these, we find 17 defective devices. Does this batch have a significantly higher failure rate than our known failure rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify our inputs\n",
    "\n",
    "p_failure <- 0.0001      # a-priori known failure rate\n",
    "\n",
    "n_trials <- 250000        # number of devices produced\n",
    "\n",
    "n_defectives <- 17        # number of defective devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.4.1 Device Defects Example (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tExact binomial test\n",
      "\n",
      "data:  n_defectives and n_trials\n",
      "number of successes = 17, number of trials = 250000, p-value = 0.9623\n",
      "alternative hypothesis: true probability of success is greater than 1e-04\n",
      "95 percent confidence interval:\n",
      " 4.332901e-05 1.000000e+00\n",
      "sample estimates:\n",
      "probability of success \n",
      "               6.8e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run binomial test on medical device data\n",
    "\n",
    "test2 <- binom.test(n_defectives, n_trials, p = p_failure, alternative = \"greater\")\n",
    "\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Challenge Problem</h1></center>\n",
    "\n",
    "Let's use the Providence Police Departments arrests data to answer the following research question: _Is there a statistically significant difference between the number of males and females arrested?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the arrests data, then run a binomial test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Pearson's $\\chi^2$ Test for Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. Pearson's $\\chi^2$ Test\n",
    "\n",
    "What if our categorical variables has more than 2 categories?\n",
    "\n",
    "There are a few options when you have a variable with more than 2 categories\n",
    "  - Exact Multinomial Test (EMT package in _R_)\n",
    "  - _G_-Test for Goodness-of-Fit (also called likelihood ratio test)\n",
    "  - Pearson's $\\chi^2$ (Goodness-of-Fit) Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 6.1 Pearson's $\\chi^2$ (Goodness-of-Fit) Test\n",
    "Pearson's $\\chi^2$ goodness-of-fit test can be used when we have some categorical variable, $X$, where each $X_i$ is a value from one of $K$ categories, and where $K \\ge 2$ and we have an expected probability, $P_k$, for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 6.2 Pearson's $\\chi^2$ Goodness-of-Fit Test Example\n",
    "\t\t\n",
    "Suppose we want to determine whether or not a die is loaded (i.e., not a fair die). Say we roll the die 100 times, and we obtain the following results:\n",
    "\n",
    "| Face | Count |\n",
    "| :- | --- |\n",
    "| 1 | 13 |\n",
    "| 2 | 21 |\n",
    "| 3 | 15 |\n",
    "| 4 | 17 |\n",
    "| 5 | 20 |\n",
    "| 6 | 14 |\n",
    "\n",
    "\n",
    "Are we confident that this is a fair die?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6.2.1 Pearson's $\\chi^2$ Test Example (cont.)\n",
    "The test statistic is $\\chi^2$ and is computed using:\n",
    "\n",
    "$$ \\chi^{2}=\\sum _{k=1}^{K}{\\frac {(O_{k}-E_{k})^{2}}{E_{k}}},  $$\n",
    "\n",
    "where $K$ is the number of categories, $O_k$ is the observed count for category $k$, and $E_k$ is the expected count for category $k$ under the null hypothesis. The degrees of freedom are: $df = K - 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6.2.2 Pearson's $\\chi^2$ Test Example (cont.)\n",
    "The $\\chi^2$ test statistic follows the $\\chi^2$ distribution, a continuous distribution with a single parameterâ€”the degrees of freedom (i.e., $df$).\n",
    "\n",
    "<center><img src=\"images/chisq_dist.jpg\" width=\"650\"></center>\n",
    "\n",
    "[1.] Image source: https://stats.libretext.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6.2.3 Pearson's $\\chi^2$ Test Example (cont.)\n",
    "\t\n",
    "With this $\\chi^2$ and $df$, we evaluate probability of observed data if the null hypothesis is true.\n",
    "  - Note that Pearson's $\\chi^2$ goodness-of-fit test assumes observations are independent from one another\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/chisq_dist2.jpg\" width=\"650\"></center>\n",
    "\n",
    "[1.] Image source: https://actuarialmodelingtopics.wordpress.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6.2.4 Using the `chisq.test()` Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "roll_cnts <- c(13, 21, 15, 17, 20, 14)     # create vector with our counts\n",
    "\n",
    "probs <- rep(1/6, 6)                       # create vector with 6 elements, all 1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test1 <- chisq.test(roll_cnts, p = probs)  # run test\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6.2.5 Using `str()` on Output of `chisq.test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "str(test1)              # examine components of test object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1$residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Pearson's $\\chi^2$ Test of Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7. Pearson's $\\chi^2$ (Independence) Test\n",
    "\n",
    "We can also use Pearson's $\\chi^2$ to solve a different sort of problem. In particular, we can use Pearson's $\\chi^2$ to test the extent to which two categorical variables are independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 7.1 Pearson's $\\chi^2$ (Independence) Test Example\n",
    "\n",
    "Suppose we would like to teach cats to dance. \n",
    "\n",
    "\t\t\n",
    "We have two training systems: using food as a reward, and using affection as a reward. Suppose after a week of training the cats, we test dancing ability. So, we have two categorical variables: _training_ and _dance_, each with two levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "|.|.|Food as reward|Affection as reward|\n",
    "|---|---|---|---|\n",
    "|Cat Dances? |Yes| 28           | 48                |\n",
    "|     .     |No | 10           | 114               |\n",
    "\n",
    "\n",
    "From these data, are the _training_ and _dance_ variables independent?\n",
    "\n",
    "*Source: Field _et al._ (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 7.1.1 Pearson's $\\chi^2$ Independence Test (cont.)\n",
    "The test statistic is $\\chi^2$ and is computed using:\n",
    "\n",
    " $$ \\chi ^{2}=\\sum _{{i=1}}^{{r}}\\sum _{{j=1}}^{{c}} {(O_{{i,j}}-E_{{i,j}})^{2} \\over E_{{i,j}}},  $$\n",
    "\t\n",
    "where $$ E_{i,j} = { \\text{row-total}_i \\times \\text{column-total}_j \\over N} $$\n",
    "\t\n",
    "and where $O_{i,j}$ is the observed count in cell $i, j$ and $E_{i,j}$ is the expected count for cell $i,j$ under the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 7.1.2 Pearson's $\\chi^2$ Independence Test (cont.)\n",
    "Note:\n",
    "  - Degrees of freedom: $ df = (r - 1)(c - 1) $ where $r$ is the number of rows, and $c$ is the number of columns\n",
    "  - Assumption that observations are independent from one another \n",
    "    + E.g., In above example, a cat could only be in one _training_ condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 8. Pearson's $\\chi^2$ Independence Test in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "can_dance <- c(rep(TRUE, 76), rep(FALSE, 124))\n",
    "\n",
    "training <- c(rep(\"food\", 28), rep(\"affection\", 48), rep(\"food\", 10), rep(\"affection\", 114))\n",
    "\n",
    "cats <- data.frame(can_dance, training)\n",
    "\n",
    "head(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 8.1 Running $\\chi^2$ Test of Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check to make sure data are correct\n",
    "xtab1 <- table(cats$can_dance, cats$training)\n",
    "\n",
    "print(xtab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test1 <- chisq.test(cats$training, cats$can_dance)\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Continuous Variables and <i>T</i>-Tests</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 9. Introduction\n",
    "To this point, we have been looking at categorical data (e.g., \"heads\"/\"tails\", yes/no, cat dances/cat doesn't dance). We will now explore some interesting new methods; in particular, we can start looking at continuous variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10. Student's _T_-Test\n",
    "\n",
    "\n",
    "- The t-test refers to a family of statistical tests whose test statistic follows the t-distribution. \n",
    "- First published by William Gossett under pseudonym \"Student\"\n",
    "\n",
    "<center><img src=\"images/gossett.jpg\" width=180/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 10.1 _T_-Distribution\n",
    "\n",
    "- The t-distribution is a continuous probability distribution\n",
    "- Has 1 parameter \n",
    "  + $\\nu$: degrees of freedom\n",
    "- Similar to normal distribution\n",
    "  + Symmetric and bell-shaped\n",
    "  \n",
    "<center><img src=\"images/t_dist.png\" width=270/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### 10.1.1 Student's _T_-Test (cont.)\n",
    "\n",
    "We will discuss three types of _t_-tests\n",
    "  - One-sample _t_-test\n",
    "  - Independent (two-sample) _t_-test\n",
    "  - Dependent samples _t_-test\n",
    "    + Also known as \"paired-samples\" _t_-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## 10.2 Notes on _t_-tests in R\n",
    "  - All three versions of the _t_-test are implemented in R as the `t.test()`function\n",
    "  - Specifying different arguments to the function will give you different type of _t_-test\n",
    "  - In all three cases, the _t_-test can be done as one-sided or two sided. We will generally prefer two-sided tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11. One-Sample _t_-test\n",
    "The one-sample _t_-test is used to test the null hypothesis that the population mean is equal to some value $\\mu_0$. The test statistics is defined as $$t = \\frac{\\overline{x} - \\mu_0}{\\sigma_{\\overline{x}}},$$\n",
    "where $\\overline{x}$ is the sample mean and $\\sigma_{\\overline{x}}$ is our estimate of the standard error of the mean. Recall it is defined as $$\\sigma_{\\overline{x}} = {s \\over \\sqrt{n}},$$\n",
    "where $s$ is the sample standard deviation and $n$ is the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## 11.1 One-Sample _t_-test (cont.)\n",
    "So, our test statistics is defined as $$t = \\frac{\\overline{x} - \\mu_0}{s / \\sqrt{n}}.$$ We also need to know the degrees of freedoms ($\\nu$) so we can compare our $t$ to the appropriate _t_-distribution. \n",
    "\n",
    "In the one-sample case, $\\nu = n - 1$, where $n$ is our sample size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 11.1.1 One-Sample _t_-test Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you teach high school math and you would like to know whether your students perform at, above, or below average on the math portion of the SAT, which is known to be 527."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define vector of student's SAT scores\n",
    "sat <- c(527, 554, 534, 541, 539, 542, 498, 512, \n",
    "         528, 531, 563, 566, 498, 503, 551, 582, \n",
    "         529, 549, 571, 523, 543, 588, 571)\n",
    "\n",
    "# our sample mean\n",
    "mean(sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 11.1.2 One-Sample _t_-test Example (cont.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t.test(sat, mu = 527)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## 11.2 One-Sample _t_-test  Assumptions\n",
    "Assumptions of one-sample _t_-test:\n",
    "\n",
    "  - Observations are independent \n",
    "  - Variable is normally distributed in population\n",
    "    + In practice, _t_-test is fairly robust to violations of normality provided $n$ is not small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "# 12. Independent (Two-Sample) _t_-test\n",
    "The independent _t_-test:\n",
    "\n",
    "  - More common version of the _t_-test\n",
    "  - Used to compare means from two different groups\n",
    "  - Test statistic is:\n",
    "    $$t = \\frac{\\overline{x}_1 - \\overline{x}_2}{\\sqrt{{s_{1}^{2} \\over n_1} + {s_{2}^{2} \\over n_2}}},$$\n",
    "    where $s_{k}^{2}$ is variance of Group $k$, and $n_k$ is sample size.\n",
    "\n",
    "  - Our degrees of freedom are: $\\nu = n_1 + n_2 - 2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 12.1 Two-Sample _t_-test Example\n",
    "\n",
    "  - `spider` data from Andy Field's _Discovering Statistics with R_\n",
    "  - Treating arachnophobia\n",
    "  - Two treatment groups (12 subjects per group):\n",
    "      + real spider\n",
    "      + picture of spider\n",
    "  - Measure anxiety after exposure to spider or picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "spider <- read.csv(\"data/spiderlong.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 12.1.1 Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "head(spider)\n",
    "tail(spider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 12.1.2 Examine Data (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(spider, aes(x = anxiety, fill = group)) +\n",
    "    geom_density(alpha = 0.5, colour = \"grey\") +\n",
    "    xlim(10, 85) +\n",
    "    scale_fill_manual(values = c(\"navy\", \"purple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 12.1.3 Examine Data (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(spider, aes(y = anxiety, x = group, fill = group)) +\n",
    "    geom_boxplot(width = 0.2) + \n",
    "    geom_jitter(width = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 12.2 Two-Sample _t_-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t.test(anxiety ~ group, data = spider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 12.3 Independent (two-sample) _t_-test (cont.)\n",
    "Assumptions of independent (two-sample) _t_-test:\n",
    "\n",
    "  - Observations are independent \n",
    "  - Variable is normally distributed in population\n",
    "    + In practice, _t_-test is fairly robust to violations of normality provided $n$ is not small.\n",
    "\n",
    "  - Homogeneity of variance\n",
    "\n",
    "  - Assume equal variances in two populations \n",
    "    + The _t_-test is also quite robust to violations of homogeneity of variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 13. Dependent (paired-sample) _t_-test\n",
    "\n",
    "The paired _t_-test is often used when we have repeated measurements (i.e., one sample with two measurement occasions). The test statistics is defined as $$t = \\frac{\\overline{x}_D - \\mu_0}{{s_D \\over \\sqrt{n}}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 13.1 Paired-Sample _t_-test Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Suppose we are interested in cholesterol level changes over time\n",
    "  - Recruit 100 patients each to follow over time\n",
    "  - Two time poits:\n",
    "    + Time1: baseline measurement at beginning of study\n",
    "    + Time2: after 10 years\n",
    "  - Measure their total cholesterol\n",
    "  - Research questions:\n",
    "\n",
    "<center><i>Do cholesterol levels in adults increase over time?</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 13.1.1 Paired-Sample _t_-test Example (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "chol_df <- read.csv(\"data/cholesterol_data.csv\")\n",
    "\n",
    "head(chol_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 13.1.2 Paired-Sample _t_-test Example (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(chol_df) +\n",
    "    geom_density(alpha = 0.5, colour = \"grey\", fill = \"navy\", aes(x = time1)) +\n",
    "    geom_density(alpha = 0.5, colour = \"grey\", fill = \"purple\", aes(x = time2)) +\n",
    "    xlim(80, 380)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 13.1.3 Paired-Sample _t_-test (cont.)\n",
    "\n",
    "Running paired-sample _t_-test using the `t.test()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t.test(chol_df$time1, chol_df$time2, paired = TRUE)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
